{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DatasetClass import CarlaMotionSeg\n",
    "from train import train, run_val\n",
    "from utils_train import get_dataloaders, setup_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Command Line Arguments + Define Setup Function (can be left unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--lr\", default=1.25e-5, type=float, help='Learning rate - default: 5e-3')\n",
    "    parser.add_argument(\"--batch_size\", default=1, type=int, help='Default=2')\n",
    "    parser.add_argument(\"--epochs\", default=50, type=int, help='Default=50')\n",
    "    parser.add_argument(\"--loss_type\", default='focal', type=str, help='Loss types available - focal, bce')\n",
    "    parser.add_argument(\"--patience\", default=3, type=int, help='Default=3')\n",
    "    parser.add_argument(\"--lr_scheduler_factor\", default=0.5, type=float, help=\"Learning rate multiplier - default: 3\")\n",
    "    parser.add_argument(\"--alpha\", default=0.25, type=float, help='Focal loss alpha - default: 0.25')\n",
    "    parser.add_argument(\"--gamma\", default=2.0, type=float, help='Focal loss gamma - default: 2')\n",
    "    parser.add_argument(\"--load_chkpt\", '-chkpt', default='0', type=str, help=\"Loading entire checkpoint path for inference/continue training\")\n",
    "    parser.add_argument(\"--dataset_fraction\", default=0.002, type=float, help=\"fraction of dataset to be used\")\n",
    "    return parser\n",
    "\n",
    "def train_setup(args):\n",
    "    # data_root = os.path.join(root, \"datasets/Extended_MOD_Masks/\")\n",
    "    data_root = os.path.join(args.root, \"datasets/Carla_Annotation/Carla_Export/\")\n",
    "    log_root = os.path.join(args.root, \"logs/\")\n",
    "    root_tb = os.path.join(args.root, \"runs_temp/\")\n",
    "    args.root_tb = root_tb\n",
    "\n",
    "    # define string needed for logging\n",
    "    args.now = datetime.now()\n",
    "    now_string = args.now.strftime(f\"%d-%m-%Y_%H-%M_{args.batch_size}_{args.lr}_{args.epochs}\")\n",
    "    \n",
    "    # setup logging\n",
    "    args, logger = setup_logger(args, log_root, now_string)\n",
    "\n",
    "    # log general info\n",
    "    logger.info(f\"running with lr={args.lr}, batch_size={args.batch_size}, epochs={args.epochs}, loss_type = {args.loss_type}, patience={args.patience}, lr_scheduler_factor={args.lr_scheduler_factor} alpha={args.alpha}, gamma={args.gamma}\")\n",
    "    logger.info(f\"running on '{args.device}'\")\n",
    "\n",
    "    # define dataset and get data loaders\n",
    "    dataset = CarlaMotionSeg(data_root)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(dataset, args)\n",
    "\n",
    "    # initialize tensorboard\n",
    "    args.writer = SummaryWriter(os.path.join(root_tb, now_string))\n",
    "\n",
    "    return args, logger, train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the root and run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] running with lr=1.25e-05, batch_size=1, epochs=50, loss_type = focal, patience=3, lr_scheduler_factor=0.5 alpha=0.25, gamma=2.0\n",
      "[INFO] running on 'cuda:0'\n",
      "dirs loaded:\n",
      "['0000', '0001', '0002', '0003', '0004', '0005', '0006', '0007', '0008', '0009', '0010', '0011', '0012', '0013', '0014', '0015', '0016', '0017', '0018', '0019', '0020', '0021', '0022', '0023', '0024', '0025']\n",
      "[INFO] loaded model of type: <class 'ModelClass.UNET'>\n",
      "train network ...\n",
      "[INFO] Epoch [1/50] with lr 1.25e-05, train loss: 125217.06836, val loss: 111451.07031, IoU: 0.0, ETA: 0.06 hrs\n",
      "[INFO] Epoch [2/50] with lr 1.25e-05, train loss: 118583.29492, val loss: 112133.8125, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [3/50] with lr 1.25e-05, train loss: 113322.50391, val loss: 112288.39062, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [4/50] with lr 1.25e-05, train loss: 109422.69531, val loss: 113034.08594, IoU: 0.0, ETA: 0.05 hrs\n",
      "Epoch     5: reducing learning rate of group 0 to 6.2500e-06.\n",
      "[INFO] Epoch [5/50] with lr 6.25e-06, train loss: 105577.78516, val loss: 113494.53906, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [6/50] with lr 6.25e-06, train loss: 102547.31055, val loss: 111755.85156, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [7/50] with lr 6.25e-06, train loss: 100860.96875, val loss: 107352.64062, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [8/50] with lr 6.25e-06, train loss: 99009.55273, val loss: 101357.96875, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [9/50] with lr 6.25e-06, train loss: 97207.87305, val loss: 95488.19531, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [10/50] with lr 6.25e-06, train loss: 95466.72656, val loss: 90814.70312, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch 10 Current best IoU at epoch 10\n",
      "[INFO] Epoch [11/50] with lr 6.25e-06, train loss: 93643.20508, val loss: 87200.42188, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [12/50] with lr 6.25e-06, train loss: 91847.57422, val loss: 84607.25, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [13/50] with lr 6.25e-06, train loss: 90044.60547, val loss: 82761.26562, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [14/50] with lr 6.25e-06, train loss: 88255.12695, val loss: 81518.77344, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [15/50] with lr 6.25e-06, train loss: 86426.51172, val loss: 80786.80469, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [16/50] with lr 6.25e-06, train loss: 84652.81445, val loss: 80141.51562, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [17/50] with lr 6.25e-06, train loss: 82915.60742, val loss: 79346.90625, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [18/50] with lr 6.25e-06, train loss: 81190.00977, val loss: 78312.14062, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [19/50] with lr 6.25e-06, train loss: 79529.90625, val loss: 76893.46875, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [20/50] with lr 6.25e-06, train loss: 77841.20898, val loss: 75393.07812, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch 20 Current best IoU at epoch 20\n",
      "[INFO] Epoch [21/50] with lr 6.25e-06, train loss: 76242.47266, val loss: 73717.1875, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [22/50] with lr 6.25e-06, train loss: 74621.07227, val loss: 72147.39062, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [23/50] with lr 6.25e-06, train loss: 73058.83984, val loss: 70583.48438, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [24/50] with lr 6.25e-06, train loss: 71535.38281, val loss: 68977.28906, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [25/50] with lr 6.25e-06, train loss: 70022.7207, val loss: 67407.01562, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [26/50] with lr 6.25e-06, train loss: 68541.75781, val loss: 65882.49219, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [27/50] with lr 6.25e-06, train loss: 67114.51074, val loss: 64358.44531, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [28/50] with lr 6.25e-06, train loss: 65695.46387, val loss: 62916.67969, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [29/50] with lr 6.25e-06, train loss: 64314.19336, val loss: 61559.375, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [30/50] with lr 6.25e-06, train loss: 62971.71875, val loss: 60244.76562, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch 30 Current best IoU at epoch 30\n",
      "[INFO] Epoch [31/50] with lr 6.25e-06, train loss: 61662.05762, val loss: 58951.24219, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [32/50] with lr 6.25e-06, train loss: 60378.55762, val loss: 57756.08594, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [33/50] with lr 6.25e-06, train loss: 59135.26855, val loss: 56619.59375, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [34/50] with lr 6.25e-06, train loss: 57935.41797, val loss: 55447.44922, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [35/50] with lr 6.25e-06, train loss: 56749.55176, val loss: 54349.19531, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [36/50] with lr 6.25e-06, train loss: 55630.65039, val loss: 53187.07812, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [37/50] with lr 6.25e-06, train loss: 54482.3623, val loss: 52134.5, IoU: 0.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [38/50] with lr 6.25e-06, train loss: 53414.2998, val loss: 51117.07812, IoU: 0.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [39/50] with lr 6.25e-06, train loss: 52348.40137, val loss: 50143.30469, IoU: 0.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [40/50] with lr 6.25e-06, train loss: 51342.39941, val loss: 49189.74609, IoU: 0.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch 40 Current best IoU at epoch 40\n",
      "[INFO] Epoch [41/50] with lr 6.25e-06, train loss: 50332.38477, val loss: 48268.58594, IoU: 0.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [42/50] with lr 6.25e-06, train loss: 49359.19141, val loss: 47404.42969, IoU: 0.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [43/50] with lr 6.25e-06, train loss: 48408.28906, val loss: 46552.34375, IoU: 0.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [44/50] with lr 6.25e-06, train loss: 47472.71973, val loss: 45736.87109, IoU: 0.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [45/50] with lr 6.25e-06, train loss: 46569.32812, val loss: 44909.60938, IoU: 0.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [46/50] with lr 6.25e-06, train loss: 45690.69629, val loss: 44068.3125, IoU: 0.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch [47/50] with lr 6.25e-06, train loss: 44816.86328, val loss: 43353.5625, IoU: 0.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch [48/50] with lr 6.25e-06, train loss: 44004.67188, val loss: 42559.53906, IoU: 0.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch [49/50] with lr 6.25e-06, train loss: 43205.69141, val loss: 41794.25, IoU: 0.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch [50/50] with lr 6.25e-06, train loss: 42436.73633, val loss: 41204.58984, IoU: 0.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch 50 Current best IoU at epoch 50\n"
     ]
    }
   ],
   "source": [
    "args = parse().parse_args(\"\")\n",
    "args.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "args.root = \"/storage/remote/atcremers40/motion_seg/\"\n",
    "\n",
    "args, logger, train_loader, val_loader = train_setup(args)\n",
    "train(args, train_loader, val_loader, None, logger)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1defcf583daa72ff2562ab5259c869074eb4282387c5d4b161f752a4f80423e5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
