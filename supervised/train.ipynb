{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DatasetClass import CarlaMotionSeg\n",
    "from train import train, run_val\n",
    "from utils_train import get_dataloaders, setup_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Command Line Arguments + Define Setup Function (can be left unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--lr\", default=1.25e-5, type=float, help='Learning rate - default: 5e-3')\n",
    "    parser.add_argument(\"--batch_size\", default=1, type=int, help='Default=2')\n",
    "    parser.add_argument(\"--epochs\", default=50, type=int, help='Default=50')\n",
    "    parser.add_argument(\"--loss_type\", default='focal', type=str, help='Loss types available - focal, bce')\n",
    "    parser.add_argument(\"--patience\", default=3, type=int, help='Default=3')\n",
    "    parser.add_argument(\"--lr_scheduler_factor\", default=0.5, type=float, help=\"Learning rate multiplier - default: 3\")\n",
    "    parser.add_argument(\"--alpha\", default=0.25, type=float, help='Focal loss alpha - default: 0.25')\n",
    "    parser.add_argument(\"--gamma\", default=2.0, type=float, help='Focal loss gamma - default: 2')\n",
    "    parser.add_argument(\"--load_chkpt\", '-chkpt', default='0', type=str, help=\"Loading entire checkpoint path for inference/continue training\")\n",
    "    parser.add_argument(\"--dataset_fraction\", default=0.002, type=float, help=\"fraction of dataset to be used\")\n",
    "    return parser\n",
    "\n",
    "def train_setup(args):\n",
    "    # data_root = os.path.join(root, \"datasets/Extended_MOD_Masks/\")\n",
    "    data_root = os.path.join(args.root, \"datasets/Carla_supervised\")\n",
    "    log_root = os.path.join(args.root, \"logs/\")\n",
    "    root_tb = os.path.join(args.root, \"runs_temp/\")\n",
    "    args.root_tb = root_tb\n",
    "\n",
    "    # define string needed for logging\n",
    "    args.now = datetime.now()\n",
    "    now_string = args.now.strftime(f\"%d-%m-%Y_%H-%M_{args.batch_size}_{args.lr}_{args.epochs}\")\n",
    "    \n",
    "    # setup logging\n",
    "    args, logger = setup_logger(args, log_root, now_string)\n",
    "\n",
    "    # log general info\n",
    "    logger.info(f\"running with lr={args.lr}, batch_size={args.batch_size}, epochs={args.epochs}, loss_type = {args.loss_type}, patience={args.patience}, lr_scheduler_factor={args.lr_scheduler_factor} alpha={args.alpha}, gamma={args.gamma}\")\n",
    "    logger.info(f\"running on '{args.device}'\")\n",
    "\n",
    "    # define dataset and get data loaders\n",
    "    dataset = CarlaMotionSeg(data_root)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(dataset, args)\n",
    "\n",
    "    # initialize tensorboard\n",
    "    args.writer = SummaryWriter(os.path.join(root_tb, now_string))\n",
    "\n",
    "    return args, logger, train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the root and run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] running with lr=1.25e-05, batch_size=1, epochs=50, loss_type = focal, patience=3, lr_scheduler_factor=0.5 alpha=0.25, gamma=2.0\n",
      "[INFO] running on 'cuda:0'\n",
      "dirs loaded:\n",
      "['0000', '0001', '0002', '0003', '0004', '0005', '0006', '0007', '0008', '0009', '0010', '0011', '0012', '0013', '0014', '0015', '0016', '0017', '0018', '0019', '0020', '0021', '0022', '0023', '0024', '0025']\n",
      "[INFO] loaded model of type: <class 'ModelClass.UNET'>\n",
      "train network ...\n",
      "[INFO] Epoch [1/50] with lr 1.25e-05, train loss: 66898.03516, val loss: 81329.00781, IoU: 1.0, ETA: 0.06 hrs\n",
      "[INFO] Epoch [2/50] with lr 1.25e-05, train loss: 62940.96191, val loss: 80591.46875, IoU: 1.0, ETA: 0.06 hrs\n",
      "[INFO] Epoch [3/50] with lr 1.25e-05, train loss: 60246.75391, val loss: 80227.69531, IoU: 1.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [4/50] with lr 1.25e-05, train loss: 57983.16992, val loss: 79684.50781, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [5/50] with lr 1.25e-05, train loss: 55568.93848, val loss: 78176.53125, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [6/50] with lr 1.25e-05, train loss: 53490.45898, val loss: 74729.03125, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [7/50] with lr 1.25e-05, train loss: 51710.95508, val loss: 69505.125, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [8/50] with lr 1.25e-05, train loss: 49730.2207, val loss: 62089.17969, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [9/50] with lr 1.25e-05, train loss: 47998.35352, val loss: 54355.62891, IoU: 0.0, ETA: 0.05 hrs\n",
      "[INFO] Epoch [10/50] with lr 1.25e-05, train loss: 46234.00586, val loss: 47604.59375, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch 10 Current best IoU at epoch 3\n",
      "[INFO] Epoch [11/50] with lr 1.25e-05, train loss: 44466.86621, val loss: 43012.64453, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [12/50] with lr 1.25e-05, train loss: 42728.10059, val loss: 39960.10156, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [13/50] with lr 1.25e-05, train loss: 41064.65137, val loss: 37779.65625, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [14/50] with lr 1.25e-05, train loss: 39489.49316, val loss: 35998.94531, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [15/50] with lr 1.25e-05, train loss: 37931.64648, val loss: 34417.95312, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [16/50] with lr 1.25e-05, train loss: 36394.46875, val loss: 33072.25, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [17/50] with lr 1.25e-05, train loss: 35034.97314, val loss: 31946.09961, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [18/50] with lr 1.25e-05, train loss: 33563.45215, val loss: 30871.60938, IoU: 0.0, ETA: 0.04 hrs\n",
      "[INFO] Epoch [19/50] with lr 1.25e-05, train loss: 32206.10596, val loss: 29784.75391, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [20/50] with lr 1.25e-05, train loss: 30921.68701, val loss: 28715.30664, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch 20 Current best IoU at epoch 3\n",
      "[INFO] Epoch [21/50] with lr 1.25e-05, train loss: 29632.27832, val loss: 27550.35938, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [22/50] with lr 1.25e-05, train loss: 28469.57031, val loss: 26620.79102, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [23/50] with lr 1.25e-05, train loss: 27302.20117, val loss: 25672.54102, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [24/50] with lr 1.25e-05, train loss: 26225.53711, val loss: 24748.39258, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [25/50] with lr 1.25e-05, train loss: 25210.62158, val loss: 23868.54297, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [26/50] with lr 1.25e-05, train loss: 24283.89697, val loss: 23048.23242, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [27/50] with lr 1.25e-05, train loss: 23448.39893, val loss: 22306.04297, IoU: 0.0, ETA: 0.03 hrs\n",
      "[INFO] Epoch [28/50] with lr 1.25e-05, train loss: 22567.76318, val loss: 21592.25195, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [29/50] with lr 1.25e-05, train loss: 21789.73291, val loss: 20615.42383, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [30/50] with lr 1.25e-05, train loss: 21077.64697, val loss: 20111.65234, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch 30 Current best IoU at epoch 3\n",
      "[INFO] Epoch [31/50] with lr 1.25e-05, train loss: 21206.49023, val loss: 20227.8457, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [32/50] with lr 1.25e-05, train loss: 20348.78564, val loss: 20740.19141, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [33/50] with lr 1.25e-05, train loss: 20477.23828, val loss: 20500.05469, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [34/50] with lr 1.25e-05, train loss: 20017.86035, val loss: 20016.54102, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [35/50] with lr 1.25e-05, train loss: 19355.73633, val loss: 19372.40039, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [36/50] with lr 1.25e-05, train loss: 18640.60645, val loss: 18646.84766, IoU: 0.0, ETA: 0.02 hrs\n",
      "[INFO] Epoch [37/50] with lr 1.25e-05, train loss: 18099.48975, val loss: 18082.47656, IoU: 0.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [38/50] with lr 1.25e-05, train loss: 17553.09229, val loss: 17422.20703, IoU: 1.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [39/50] with lr 1.25e-05, train loss: 17049.02246, val loss: 16809.27734, IoU: 1.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [40/50] with lr 1.25e-05, train loss: 16628.28662, val loss: 16204.36719, IoU: 1.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch 40 Current best IoU at epoch 40\n",
      "[INFO] Epoch [41/50] with lr 1.25e-05, train loss: 16244.78101, val loss: 15771.85254, IoU: 1.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [42/50] with lr 1.25e-05, train loss: 15867.71216, val loss: 15475.24805, IoU: 1.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [43/50] with lr 1.25e-05, train loss: 15534.29395, val loss: 15153.14844, IoU: 1.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [44/50] with lr 1.25e-05, train loss: 15213.65039, val loss: 14871.18359, IoU: 1.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [45/50] with lr 1.25e-05, train loss: 14925.13354, val loss: 14616.23438, IoU: 1.0, ETA: 0.01 hrs\n",
      "[INFO] Epoch [46/50] with lr 1.25e-05, train loss: 14659.57227, val loss: 14366.93359, IoU: 1.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch [47/50] with lr 1.25e-05, train loss: 14398.34961, val loss: 14130.6709, IoU: 1.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch [48/50] with lr 1.25e-05, train loss: 14148.57129, val loss: 13887.25977, IoU: 1.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch [49/50] with lr 1.25e-05, train loss: 13924.96753, val loss: 13700.99316, IoU: 1.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch [50/50] with lr 1.25e-05, train loss: 13698.52368, val loss: 13470.64844, IoU: 1.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch 50 Current best IoU at epoch 50\n"
     ]
    }
   ],
   "source": [
    "args = parse().parse_args(\"\")\n",
    "args.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "args.root = \"/storage/remote/atcremers40/motion_seg/\"\n",
    "\n",
    "args, logger, train_loader, val_loader = train_setup(args)\n",
    "train(args, train_loader, val_loader, None, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to run the cells below, plese run below command in terminal:\n",
    "```sh\n",
    "ssh -L 8888:localhost:8888 -L 6015:localhost:6015 ~UserName~@atcremers9.in.tum.de -p 58022\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard #Uncomment if tensorboard is already running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6015 (pid 531999), started 0:19:54 ago. (Use '!kill 531999' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a8e37713bda9dbe9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a8e37713bda9dbe9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6015;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir log_root --bind_all --port 6015"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1defcf583daa72ff2562ab5259c869074eb4282387c5d4b161f752a4f80423e5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
