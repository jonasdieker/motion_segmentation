{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DatasetClass import CarlaUnsupervised\n",
    "from train import train, run_val\n",
    "from utils_train import get_dataloaders, setup_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Command Line Arguments + Define Setup Function (can be left unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--lr\", default=5e-4, type=float, help='Learning rate - default: 5e-5')\n",
    "    parser.add_argument(\"--batch_size\", default=1, type=int, help='Default=2')\n",
    "    parser.add_argument(\"--epochs\", default=10, type=int, help='Default=50')\n",
    "    parser.add_argument(\"--patience\", default=6, type=float, help='Default=3')\n",
    "    parser.add_argument(\"--lr_scheduler_factor\", default=0.5, type=float, help=\"Learning rate multiplier - default: 3\")\n",
    "    parser.add_argument(\"--alpha\", default=0.25, type=float, help='Focal loss alpha - default: 0.25')\n",
    "    parser.add_argument(\"--gamma\", default=2.0, type=float, help='Focal loss gamma - default: 2')\n",
    "    parser.add_argument(\"--l_M\", default=0.005, type=float, help=\"hyper-param for motion seg loss\")\n",
    "    parser.add_argument(\"--l_C\", default=0.3, type=float, help=\"hyper-param for consensus loss\")\n",
    "    parser.add_argument(\"--l_S\", default=1.0, type=float, help=\"hyper-param for regularization\")\n",
    "    parser.add_argument(\"--load_chkpt\", '-chkpt', default='0', type=str, help=\"Loading entire checkpoint path for inference/continue training\")\n",
    "    parser.add_argument(\"--dataset_fraction\", default=0.001, type=float, help=\"fraction of dataset to be used\")\n",
    "    return parser\n",
    "\n",
    "def train_setup(args):\n",
    "    data_root = os.path.join(args.root, \"datasets/CARLA/\")\n",
    "    log_root = os.path.join(args.root, \"logs/\")\n",
    "    root_tb = os.path.join(args.root, \"runs_temp/\")\n",
    "    args.root_tb = root_tb\n",
    "\n",
    "    # define string needed for logging\n",
    "    args.now = datetime.now()\n",
    "    now_string = args.now.strftime(f\"%d-%m-%Y_%H-%M_{args.batch_size}_{args.lr}_{args.epochs}\")\n",
    "    \n",
    "    # setup logging\n",
    "    args, logger = setup_logger(args, log_root, now_string)\n",
    "\n",
    "    # log general info\n",
    "    logger.info(f\"running with lr={args.lr}, batch_size={args.batch_size}, epochs={args.epochs}, patience={args.patience}, lr_scheduler_factor={args.lr_scheduler_factor} alpha={args.alpha}, gamma={args.gamma}\")\n",
    "    logger.info(f\"running on '{args.device}'\")\n",
    "\n",
    "    # define dataset and get data loaders\n",
    "    # test=True test kwarg needed for plotting ground truth in tensorboard\n",
    "    dataset = CarlaUnsupervised(data_root, test=True)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(dataset, args)\n",
    "\n",
    "    # initialize tensorboard\n",
    "    args.writer = SummaryWriter(os.path.join(root_tb, now_string))\n",
    "\n",
    "    return args, logger, train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with default args except very small `dataset_fraction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] running with lr=0.0005, batch_size=1, epochs=10, patience=6, lr_scheduler_factor=0.5 alpha=0.25, gamma=2.0\n",
      "[INFO] running on 'cuda:0'\n",
      "[INFO] loaded model of type: <class 'ModelClass.UNET'>\n",
      "train network ...\n",
      "[INFO] Epoch [1/10] with lr 0.0005, train loss: 2356.51831, val loss: 2533.63501, IoU: 0.0919, ETA: 0.01 hrs\n",
      "[INFO] Epoch [2/10] with lr 0.0005, train loss: 2137.64221, val loss: 2561.77686, IoU: 0.0919, ETA: 0.01 hrs\n",
      "[INFO] Epoch [3/10] with lr 0.0005, train loss: 1879.51855, val loss: 2500.43164, IoU: 0.09785, ETA: 0.01 hrs\n",
      "[INFO] Epoch [4/10] with lr 0.0005, train loss: 1651.33173, val loss: 3617.70996, IoU: 0.0925, ETA: 0.01 hrs\n",
      "[INFO] Epoch [5/10] with lr 0.0005, train loss: 1457.88318, val loss: 10790.37793, IoU: 0.09295, ETA: 0.0 hrs\n",
      "[INFO] Epoch [6/10] with lr 0.0005, train loss: 1348.54993, val loss: 11014.74902, IoU: 0.09504, ETA: 0.0 hrs\n",
      "[INFO] Epoch [7/10] with lr 0.0005, train loss: 1220.72748, val loss: 3682.89233, IoU: 0.10493, ETA: 0.0 hrs\n",
      "[INFO] Epoch [8/10] with lr 0.0005, train loss: 1168.27435, val loss: 2461.9375, IoU: 0.14168, ETA: 0.0 hrs\n",
      "[INFO] Epoch [9/10] with lr 0.0005, train loss: 1112.87195, val loss: 1647.41528, IoU: 0.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch [10/10] with lr 0.0005, train loss: 1072.35547, val loss: 1429.60291, IoU: 0.0, ETA: 0.0 hrs\n",
      "[INFO] Epoch 10 Current best IoU at epoch 8\n"
     ]
    }
   ],
   "source": [
    "args = parse().parse_args(\"\")\n",
    "args.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "args.root = \"/storage/remote/atcremers40/motion_seg/\"\n",
    "\n",
    "args, logger, train_loader, val_loader = train_setup(args)\n",
    "train(args, train_loader, val_loader, None, logger)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1defcf583daa72ff2562ab5259c869074eb4282387c5d4b161f752a4f80423e5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('week5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
